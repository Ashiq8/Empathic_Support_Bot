import os
import sys
from dotenv import load_dotenv
from textblob import TextBlob

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
from langchain_community.embeddings import HuggingFaceEmbeddings


# ==================================================
# 1Ô∏è‚É£ LOAD ENV
# ==================================================
load_dotenv()

if not os.getenv("GROQ_API_KEY"):
    print("‚ùå GROQ_API_KEY not found in .env")
    sys.exit()

print("ü§ñ Empathic AI Support Bot Starting...")
print("üìÑ Loading policy document...")


# ==================================================
# 2Ô∏è‚É£ LOAD POLICY FILE
# ==================================================
loader = TextLoader("data/policy.txt", encoding="utf-8")
documents = loader.load()


# ==================================================
# 3Ô∏è‚É£ SPLIT TEXT
# ==================================================
text_splitter = CharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
texts = text_splitter.split_documents(documents)


# ==================================================
# 4Ô∏è‚É£ EMBEDDINGS (LOCAL & FREE)
# ==================================================
print("üß† Creating vector memory...")

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

db = FAISS.from_documents(texts, embeddings)


# ==================================================
# 5Ô∏è‚É£ GROQ LLM (UPDATED MODEL ‚úÖ)
# ==================================================
print("üîó Connecting to Groq Brain...")

llm = ChatGroq(
    model="llama-3.1-8b-instant",   # ‚úÖ ACTIVE & FREE MODEL
    temperature=0.3
)


# ==================================================
# 6Ô∏è‚É£ RAG CHAIN
# ==================================================
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=db.as_retriever(search_kwargs={"k": 3})
)

print("‚úÖ Bot is READY!")
print("==================================================")


# ==================================================
# 7Ô∏è‚É£ CHAT LOOP + SENTIMENT
# ==================================================
while True:
    user_input = input("\nYou: ").strip()

    if user_input.lower() in ["quit", "exit", "bye"]:
        print("Bot: Bye üëã")
        break

    # ‚ù§Ô∏è Sentiment analysis
    polarity = TextBlob(user_input).sentiment.polarity
    if polarity < -0.3:
        mood = "ANGRY üò°"
        prefix = "I'm really sorry for the inconvenience. Let me help you right away. "
    else:
        mood = "NORMAL üôÇ"
        prefix = ""

    try:
        response = qa_chain.invoke({"query": user_input})
        print(f"Bot (Mood: {mood}): {prefix}{response['result']}")
    except Exception as e:
        print(f"‚ùå Error: {e}")
